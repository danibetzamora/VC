{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea 1: Reconocimiento de matrículas básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Usuario\\Documents\\ULPGC 2023-2024\\VC\\Repositorio GitHub\\VC\\Prctica 5\\coche3.jpeg: 384x640 1 car, 171.0ms\n",
      "Speed: 8.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.9405])\n",
      "data: tensor([[1.7059e+02, 1.0196e+02, 9.7009e+02, 5.9270e+02, 9.4050e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (675, 1200)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[570.3412, 347.3297, 799.5043, 490.7334]])\n",
      "xywhn: tensor([[0.4753, 0.5146, 0.6663, 0.7270]])\n",
      "xyxy: tensor([[170.5891, 101.9630, 970.0934, 592.6964]])\n",
      "xyxyn: tensor([[0.1422, 0.1511, 0.8084, 0.8781]])\n",
      "Confidence ---> 0.95\n",
      "Class name --> car\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Guardamos imagen en variable\n",
    "coche = cv2.imread(\"coche3.jpeg\")\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "results = model(\"coche3.jpeg\")\n",
    "\n",
    "# Para cada detección\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "\n",
    "    print(boxes)\n",
    "\n",
    "    for box in boxes:\n",
    "        # Contenedor\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "        \n",
    "        # Confianza\n",
    "        confidence = math.ceil((box.conf[0]*100))/100\n",
    "        print(\"Confidence --->\",confidence)\n",
    "\n",
    "        # Clase\n",
    "        cls = int(box.cls[0])\n",
    "        print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "        # Convierte identificador numérico de clase a un color RGB\n",
    "        escala = int((cls / len(classNames)) * 255 * 3)\n",
    "        if escala >= 255*2:\n",
    "            R = 255\n",
    "            G = 255\n",
    "            B = escala - 255*2\n",
    "        else:\n",
    "            if escala >= 255:\n",
    "                R = 255\n",
    "                G = escala - 255\n",
    "                B = 0\n",
    "            else:\n",
    "                R = escala\n",
    "                G = 0\n",
    "                B = 0\n",
    "\n",
    "        # Dibuja el contenedor y clase\n",
    "        cv2.rectangle(coche, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "        cv2.putText(coche, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', coche)\n",
    "\n",
    "        cv2.waitKey(-1)\n",
    "\n",
    "        # Destruye ventanas\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 99.3ms\n",
      "Speed: 0.0ms preprocess, 99.3ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrícula: YL eg Cae\n",
      "\n",
      "Matrícula: ES\n",
      "\n",
      "Matrícula: Sern\n",
      "\n",
      "Matrícula: 202 AP\n",
      "\n",
      "Matrícula: >\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output \n",
    "import numpy as np\n",
    "import cv2  \n",
    "import math \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_car = YOLO('yolov8n.pt')\n",
    "\n",
    "# Guardamos imagen en variable\n",
    "coche = cv2.imread(\"coche3.jpeg\")\n",
    "\n",
    "plates = []\n",
    "\n",
    "# Detectar coches\n",
    "results_cars = model_car(coche)\n",
    "\n",
    "# Para cada detección de coche\n",
    "for r_car in results_cars:\n",
    "    boxes_car = r_car.boxes\n",
    "\n",
    "    for box_car in boxes_car:\n",
    "        # Coordenadas del cuadro del coche\n",
    "        x1_car, y1_car, x2_car, y2_car = box_car.xyxy[0]\n",
    "\n",
    "        # Definir la región inferior para buscar matrículas\n",
    "        roi_bottom = coche[int((y1_car + y2_car) / 2):int(y2_car), int(x1_car):int(x2_car)]\n",
    "\n",
    "        # Convertir la región a escala de grises\n",
    "        gray_roi_bottom = cv2.cvtColor(roi_bottom, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplicar umbralización adaptativa\n",
    "        _, thresh = cv2.threshold(gray_roi_bottom, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        cv2.imshow('Thresh', thresh)\n",
    "\n",
    "        # Buscar contornos en la región inferior\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filtrar contornos\n",
    "        for contour in contours:\n",
    "            # Filtrar por área del contorno\n",
    "            area = cv2.contourArea(contour)\n",
    "            if 500 < area < 5000:  # Ajusta estos valores según tu caso\n",
    "\n",
    "                # Aproximación de polígono para evaluar la forma\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                # Filtrar por la relación de aspecto y la forma\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = float(w) / h\n",
    "                if 2 < aspect_ratio < 5 and len(approx) >=4:\n",
    "                    # Ajustar las coordenadas al espacio global de la imagen\n",
    "                    x, y, w, h = int(x + x1_car), int(y + (y1_car + y2_car) / 2), int(w), int(h)\n",
    "\n",
    "                    # Extraer la región de la matrícula como una nueva imagen\n",
    "                    license_plate_region = coche[y:y + h, x+10:x + w]\n",
    "                    # Aplicar pytesseract a la región de la matrícula\n",
    "                    text = pytesseract.image_to_string(license_plate_region, config='--psm 8', output_type=Output.STRING)\n",
    "\n",
    "                    if text in plates:\n",
    "                        continue\n",
    "\n",
    "                    print(\"Matrícula:\", text)\n",
    "\n",
    "\n",
    "                    plates.append(text)\n",
    "\n",
    "                    # Dibujar cuadro alrededor del contorno\n",
    "                    cv2.rectangle(coche, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                    cv2.imshow('Matrícula', license_plate_region)\n",
    "                    \n",
    "                            \n",
    "\n",
    "# Muestra la imagen con las detecciones\n",
    "cv2.imshow('Vid', coche)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 truck, 105.8ms\n",
      "Speed: 8.4ms preprocess, 105.8ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output \n",
    "import numpy as np\n",
    "import cv2  \n",
    "import math \n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "model_car = YOLO('yolov8n.pt')\n",
    "\n",
    "# Guardamos imagen en variable\n",
    "coche = cv2.imread(\"coche2.jpg\")\n",
    "\n",
    "plates = []\n",
    "\n",
    "# Detectar coches\n",
    "results_cars = model_car(coche)\n",
    "\n",
    "# Para cada detección de coche\n",
    "for r_car in results_cars:\n",
    "    boxes_car = r_car.boxes\n",
    "\n",
    "    for box_car in boxes_car:\n",
    "        # Coordenadas del cuadro del coche\n",
    "        x1_car, y1_car, x2_car, y2_car = box_car.xyxy[0]\n",
    "\n",
    "        # Definir la región inferior para buscar matrículas\n",
    "        roi_bottom = coche[int((y1_car + y2_car) / 2):int(y2_car), int(x1_car):int(x2_car)]\n",
    "\n",
    "        # Convertir la región a escala de grises\n",
    "        gray_roi_bottom = cv2.cvtColor(roi_bottom, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Mostrar imagen con matplotlib\n",
    "        # plt.imshow(gray_roi_bottom, cmap=\"gray\")\n",
    "\n",
    "        # def plot_images(img1, img2, title1=\"\", title2=\"\"):\n",
    "        #     fig = plt.figure(figsize=[15,15])\n",
    "        #     ax1 = fig.add_subplot(121)\n",
    "        #     ax1.imshow(img1, cmap=\"gray\")\n",
    "        #     ax1.set(xticks=[], yticks=[], title=title1)\n",
    "        #     ax2 = fig.add_subplot(122)\n",
    "        #     ax2.imshow(img2, cmap=\"gray\")\n",
    "        #     ax2.set(xticks=[], yticks=[], title=title2)\n",
    "\n",
    "        # plot_images(roi_bottom, gray_roi_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea2dfb9510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Guardamos imagen en variable\n",
    "coche = cv2.imread(\"coche2.jpg\")\n",
    "gray = cv2.cvtColor(coche, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
